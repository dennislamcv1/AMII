{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>This is a draft version and the notebook is incomplete and the statements do not match the data at this point. It will be fixed soon.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your first Jupyter notebook for this course. Here, you will use scikit-learn to build and predict using decision trees. You will also see some other useful things to do that come up in the process of building and using supervised learning QuAMs. So, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order for the notebooks to function as intended, modify only between lines marked \"### begin your code here (__ lines).\" and \"### end your code here.\". \n",
    "\n",
    "- The line count is a suggestion of how many lines of code you need to accomplish what is asked.\n",
    "\n",
    "- You should execute the cells (the boxes that a notebook is composed of) in order.\n",
    "\n",
    "- You can execute a cell by pressing Shift and Enter (or Return) simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the appropriate packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we have to do is to load up some packages, including NumPy which is used for matrix and vector manipulation when you are doing scientific computing with Python and also several functions from scikit-learn!\n",
    "We will also load the pandas package, a data analysis library for Python as well as plotly, which is a cool visualization library for Python. We will also some other packages to show visualizations of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals.six import StringIO\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pydotplus import graph_from_dot_data\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy will show floating point (real) numbers in the scientific notation. Let's turn that off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data into a pandas data frame (`DataFrame`), which are good tools for manipulating, an in our case for now, displaying the data. We will load our data from a CSV (Comma-Separated Values) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_decision_trees.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very good practice to check your data before trying to build a QuAM. We are talking about the methods themselves now. This seems optional because we have clean and completely useful data and we know exactly what we want to do. However, this will become a crucial thing to do once you get into real-world applications since you have to understand your data and convert it into a useful form. Oftentimes, that is one of the parts of the machine learning process that is going to take the most time. That process will be the focus of later courses in the specialization. However, let's do the good practice anyway. Some of our best tools for checking our data is to see them in tables and figures.\n",
    "\n",
    "So, let's take a peek at our data (as a table) to see if everything is alright. We will ask the Jupyter notebook to show the data frame object `df` that we loaded with the data from the CSV file. Calling an object will let us inspect that object and in the case of pandas data frames, this shows us the data frame as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. Everything seems fine. One of the other tools for checking our data is visualizing the data. However, our data has more than 3 features, so we cannot directly visualize it (We can directly see only up to 3D). One good way to check for statistical shape of the data is to use a matrix of scatter plots. We can get a feel for the distribution of our data using that.\n",
    "\n",
    "We are using data visualization tools from the plotly package. We are going to ask plotly to show us a scatter matrix. However, we care only to see the dimensions of the data that are features and the label part should be used to show different classes in different colours. Also, the plotly will try to fit the entire scatter matrix to the width of our screen and with data with high number features, we don't want that because it may give small pairwise scatter plots, so let's specify a size of 256 pixels for the size of each scatter plot. We ask plotly to create a figure for us and show it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dimensions = df.columns[:-1].to_list()\n",
    "figure_size = df.shape[1] * 256\n",
    "\n",
    "fig = px.scatter_matrix(df, dimensions=data_dimensions, color='Label', width=figure_size, height=figure_size)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything seems good, let's get our data as NumPy arrays that will be used by scikit-learn algorithms. Our data `X` will be a matrix which has different datapoints in different rows and different features in different columns and since the `'Label'` column of the datafram `df` is not a feature of the data (but rather the label), let's exclude that. Then, our labels (or _targets_) `y` will be a vector consisting of simply that `'Label'` column of data frame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Label', axis=1).to_numpy()\n",
    "y = df['Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if everything is fine. Let's see our data `X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now let's check the shape of `X`. We should have 1870 rows since we have 1870 datapoints and we should have 7 columns since there are 7 fetaures on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same check with the targets vector `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the shape of `y` should be the same number of rows and singular in column (so there is only a row dimension and no column dimension):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Everything looks fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remeber we emphasized the importance of splitting your data into train, validation and held-out test sets? Let's put that into use. We will talk about this splitting later on in this course and you don't need to understand how this function works, however, we will provide a short explanation for those of you who are interested.\n",
    "\n",
    "Unfortunately, scikit-learn does not have a function to divide the data into three parts, only a function that splits the data into two. So, we are goign to call that function twice, once to split data into two sets: _a._ training; and _b._ validation and test combined. Then, we call the function once more to split that second set into distinct validation and test sets. We chose to reserve 0.4 (or 40%) of our data for validation and test and 1 - 0.4 = 0.6 or 60% of our data for training. From the 40% left for validation and test, we are going to use 0.5 or 50% of it (which make sit 20% of the total amount of data) for validation and the other 50% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_vt, y_train, y_vt) = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "(X_validation, X_test, y_validation, y_test) = train_test_split(X_vt, y_vt, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and fitting a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's time to build your decision tree. Remember, we create an object of the class `DecisionTreeClassifier` first. Let's set the name `dtree` for that object. In Python, you create an object of class `Clss` with its parameter `par` set to value `val` and assign it a name of `obj` by saying:\n",
    "\n",
    "`obj = Clss(par=val)`\n",
    "\n",
    "You can see the documentation for `DecisionTreeClassifier` here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "So, go ahead and create that decision tree now (also remember we are not specifying any parametes for our decision tree this time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### begin your code here (1 line).\n",
    "\n",
    "### end your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to train our decision tree model. Again, remember we use the function (or method) `fit` of our decision tree object to do that. In Python, you call a method `mthd_a` of an object `obj`, which takes arguments `arg_a1` and `arg_a2` by saying:\n",
    "\n",
    "`obj.mthd_a(arg_a1, arg_a2)`\n",
    "\n",
    "You can see the documentation for `fit` method here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit\n",
    "\n",
    "Now, go ahead and fit your `dtree` to the training data and don't forget to pass the `X_train` training data and `y_train` training targets required for fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### begin your code here (1 line).\n",
    "\n",
    "### end your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went on fine, you should be seeing a summary of the model you trained:\n",
    "\n",
    "\n",
    "> DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    ">              max_features=None, max_leaf_nodes=None,\n",
    ">              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    ">              min_samples_leaf=1, min_samples_split=2,\n",
    ">              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    ">              splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize our decision tree. Let's export our model as a special kind of data, create a visual representation form that, generate a graph from that representation and show that graph as an image (it may be a big image, so you may have to scroll to see the whole thing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(dtree, out_file=dot_data, filled=True, rounded=True, impurity=False, special_characters=True)\n",
    "graph = graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png(), unconfined=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assessment and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's evaluate our QuAM. First, let's see what happened on training data. You are going to put in the code that asks our decision tree `dtree` to predict the label for training data `X_train` and assign it to a vector variable `yhat_train`. Remember that the `predict` is the name of the method that asks a model object to predict labels. Again, you call a method `mthd_b` of an object `obj` that takes argument `arg_b1` and assign it to a variable `var` by doing:\n",
    "\n",
    "`var = obj.mthd_b(arg_b1)`\n",
    "\n",
    "You can see the documentation for `predict` method here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict\n",
    "\n",
    "So predict the labels of the training data and assign it to `yhat_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### begin your code here (1 line).\n",
    "\n",
    "### end your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can assess the accuracy of our classification model between the `yhat_train` you computed and the actual alebls that came with the training data, `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(yhat_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect 1.0 or 100%! However, that was what was expected given the minimum leaf size was 1, we let the decision tree split leafs with even 2 points in them and we had no tree depth limittation among other things.\n",
    "\n",
    "Let's use our validation data then. Calculate `yhat_validation` by asking `dtree` to predict labels for `X_validation`. Then, we can calculate the score for validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### begin your code here (1 line).\n",
    "\n",
    "### end your code here.\n",
    "accuracy_score(yhat_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right. The accuracy on validation data is much lower (should be ~0.???? or ??.??%). Maybe we have overfit to our data. Unrestricted decision trees do that.\n",
    "\n",
    "Let's create a new decision tree object `dtree2`, but this time let's set a minimum number of samples per leaf. Let's do 15. Go ahead and create `dtree2`, however, this time specify that you want the `min_samples_leaf` to be set to 15. Then, just fit your model to the training data and targets, `X_train` and `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### begin your code here (2 lines).\n",
    "\n",
    "\n",
    "### end your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you should be getting a summary of your model parameters if everything went right. In the summary you should be seeing that `min_samples_leaf=15`:\n",
    "\n",
    "> DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    ">             max_features=None, max_leaf_nodes=None,\n",
    ">             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    ">             **min_samples_leaf=15**, min_samples_split=2,\n",
    ">             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    ">             splitter='best')\n",
    "\n",
    "Now, predict `yhat_train2`, so we can the accuracy on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### begin your code here (1 line).\n",
    "\n",
    "### end your code here.\n",
    "accuracy_score(yhat_train2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracy is predictably lower (~0.???? or ??.??%) as we restrcited our decision tree, so it does not fit perfectly to training data because of its constraints.\n",
    "\n",
    "Let's predict `yhat_validation2` and we can the accuracy on validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### begin your code here (1 line).\n",
    "\n",
    "### end your code here.\n",
    "accuracy_score(yhat_validation2, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! We have a better score (~0.???? or ??.??%) on validation points. We may be ovefitting less this time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use the test data to get a final accuracy performance number for our model. Predict `yhat_test2` using `dtree2`. We can then calculate the accuracy on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### begin your code here (1 line).\n",
    "\n",
    "### end your code here.\n",
    "accuracy_score(yhat_test2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! The accuracy on test data (~0.???? or ??.??%), on validation data and on training data are close to each other, which is a good sign.\n",
    "\n",
    "Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
